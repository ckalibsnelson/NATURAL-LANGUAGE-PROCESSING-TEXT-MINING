{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP Project - Group B.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "jekyll": {
      "keywords": "fastai",
      "summary": "Application to NLP, including ULMFiT fine-tuning",
      "title": "text"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coUhsrt20sOI"
      },
      "source": [
        "# Google Colab Configuration\n",
        "\n",
        "**Execute this steps to configure the Google Colab environment in order to execute this notebook. It is not required if you are executing it locally and you have properly configured your local environment according to what explained in the Github Repository.**\n",
        "\n",
        "The first step is to clone the repository to have access to all the data and files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMgL9W4-0wXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daefd556-1c59-4f2d-f567-e5430f28ef19"
      },
      "source": [
        "! git clone https://github.com/acastellanos-ie/MBD-EN-BL-ENE-2020-J-1.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MBD-EN-BL-ENE-2020-J-1'...\n",
            "remote: Enumerating objects: 4527, done.\u001b[K\n",
            "remote: Counting objects: 100% (4527/4527), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4347/4347), done.\u001b[K\n",
            "remote: Total 4527 (delta 190), reused 4480 (delta 161), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (4527/4527), 13.46 MiB | 21.81 MiB/s, done.\n",
            "Resolving deltas: 100% (190/190), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gAhosq70ypp"
      },
      "source": [
        "Install the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy8O4JuL00hJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8cb84f6-47af-45d7-b142-a74330951ba0"
      },
      "source": [
        "! pip install -r MBD-EN-BL-ENE-2020-J-1/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/amaiya/eli5@tfkeras_0_10_1 (from -r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 12))\n",
            "  Cloning https://github.com/amaiya/eli5 (to revision tfkeras_0_10_1) to /tmp/pip-req-build-2kgk50wv\n",
            "  Running command git clone -q https://github.com/amaiya/eli5 /tmp/pip-req-build-2kgk50wv\n",
            "  Running command git checkout -b tfkeras_0_10_1 --track origin/tfkeras_0_10_1\n",
            "  Switched to a new branch 'tfkeras_0_10_1'\n",
            "  Branch 'tfkeras_0_10_1' set up to track remote branch 'tfkeras_0_10_1' from 'origin'.\n",
            "Collecting git+https://github.com/amaiya/stellargraph@no_tf_dep_082 (from -r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 13))\n",
            "  Cloning https://github.com/amaiya/stellargraph (to revision no_tf_dep_082) to /tmp/pip-req-build-c26m23j9\n",
            "  Running command git clone -q https://github.com/amaiya/stellargraph /tmp/pip-req-build-c26m23j9\n",
            "  Running command git checkout -b no_tf_dep_082 --track origin/no_tf_dep_082\n",
            "  Switched to a new branch 'no_tf_dep_082'\n",
            "  Branch 'no_tf_dep_082' set up to track remote branch 'no_tf_dep_082' from 'origin'.\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 1)) (3.2.5)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from -r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (2.2.4)\n",
            "Requirement already satisfied: en_core_web_sm from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz#egg=en_core_web_sm in /usr/local/lib/python3.7/dist-packages (from -r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 3)) (2.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 4)) (1.1.5)\n",
            "Collecting elasticsearch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/b1/58cfb0bf54e29c20669d6e588496fb7fe8b54f53bc238be4cb0a185a1e76/elasticsearch-7.13.1-py2.py3-none-any.whl (354kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 6)) (1.9.0+cu102)\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.7/dist-packages (from -r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 7)) (1.0.61)\n",
            "Collecting fastbook\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/ff/66f16fb9ceb45646e59a38ad5eb0f05fbd6524c20d9c4a2c922cdcd2955b/fastbook-0.0.16-py3-none-any.whl (720kB)\n",
            "\u001b[K     |████████████████████████████████| 727kB 15.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 9)) (0.11.1)\n",
            "Collecting tensorflow_gpu>=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/a2/5ccf0a418eb22e0a2ae9edc1e7f5456d0a4b8b49524572897564b4030a9b/tensorflow_gpu-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3MB)\n",
            "\u001b[K     |████████████████████████████████| 454.3MB 39kB/s \n",
            "\u001b[?25hCollecting ktrain\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/88/10d29578f47d0d140bf669d5598e9f5a50465ddc423b32031c65e840d003/ktrain-0.26.3.tar.gz (25.3MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3MB 138kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 14)) (4.41.1)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/92/6153f4912b84ee1ab53ab45663d23e7cf3704161cb5ef18b0c07e207cef2/transformers-4.7.0-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 12)) (21.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 12)) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 12)) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 12)) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 12)) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 12)) (0.22.2.post1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 12)) (0.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5==0.10.1->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 12)) (0.8.9)\n",
            "Collecting networkx<2.4,>=2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from stellargraph==0.8.2->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 13)) (3.2.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (57.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 5)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 6)) (3.7.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 7)) (3.13)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 7)) (7.352.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 7)) (20.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fastai->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 7)) (0.10.0+cu102)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 7)) (4.6.3)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from fastai->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 7)) (1.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 7)) (2.7.3)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (19.3.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 41.7MB/s \n",
            "\u001b[?25hCollecting nbdev>=0.2.38\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/c8/e2fba530b84a770373a106e4828ea83df62104b9694e367d169e07ea484f/nbdev-1.1.14-py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (7.6.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (1.12)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (3.3.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (0.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (0.12.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (2.5.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (1.34.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ktrain->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 11)) (5.5.0)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/72/a3add0e4eec4eb9e2569554f7c70f4a3c27712f40e3284d483e88094cc0e/langdetect-1.0.9.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 43.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 11)) (0.42.1)\n",
            "Collecting cchardet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/72/a4fba7559978de00cf44081c548c5d294bf00ac7dcda2db405d2baa8c67a/cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 46.5MB/s \n",
            "\u001b[?25hCollecting syntok\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/76/a49e73a04b3e3a14ce232e8e28a1587f8108baa665644fe8c40e307e792e/syntok-1.3.1.tar.gz\n",
            "Collecting seqeval==0.0.19\n",
            "  Downloading https://files.pythonhosted.org/packages/93/e5/b7705156a77f742cfe4fc6f22d0c71591edb2d243328dff2f8fc0f933ab6/seqeval-0.0.19.tar.gz\n",
            "Collecting keras_bert>=0.86.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/e4/3b2e2927c15c22f44005cb0ab0eaf2f7e623ea2b6488e4b7c5aca6c162c2/keras-bert-0.88.0.tar.gz\n",
            "Collecting whoosh\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 51.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 15)) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 15)) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 15)) (4.5.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 24.7MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 35.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5==0.10.1->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 12)) (2.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx<2.4,>=2.2->stellargraph==0.8.2->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 13)) (4.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph==0.8.2->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 13)) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph==0.8.2->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 13)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->stellargraph==0.8.2->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 13)) (0.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: nbconvert<6 in /usr/local/lib/python3.7/dist-packages (from nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (5.6.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (4.10.1)\n",
            "Collecting fastrelease\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/66/685d5cbd0534395a209ad04afb1573f03467ef3b430b8ee1fec24c332d0c/fastrelease-0.1.11-py3-none-any.whl\n",
            "Requirement already satisfied: jupyter-client<=6.1.12 in /usr/local/lib/python3.7/dist-packages (from nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (5.3.5)\n",
            "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (5.1.3)\n",
            "Collecting fastcore>=1.3.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b0/f1fbf554e0bf3c76e1bdc3b82eedfe41fcf656479586be38c64421082b1b/fastcore-1.3.20-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[?25hCollecting ghapi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cf/9aef37ef04f5aa8df5396750cb531cbfdc8a362d958fcad34dd4c22aa2c1/ghapi-0.1.17-py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (5.0.5)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (1.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (1.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 11)) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 11)) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 11)) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 11)) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 11)) (4.8.0)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 11)) (2.4.3)\n",
            "Collecting keras-transformer>=0.39.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/35/6b079e920fe09a9349028bc2f209447e5636d90e29c5cf060bcc3177803a/keras-transformer-0.39.0.tar.gz\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 15)) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 15)) (7.1.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (4.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (0.3)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<=6.1.12->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (22.1.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (2.6.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (5.1.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (5.3.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 11)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 11)) (0.7.0)\n",
            "Collecting keras-pos-embd>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/d2/1cc072ea68b573f366e08936177a33e237e66fa7d5338289d4bee64696cf/keras-pos-embd-0.12.0.tar.gz\n",
            "Collecting keras-multi-head>=0.28.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a5/e6/a83f26b2e1582de237b125f595874d808e40698f31d44d5903e872d5b64d/keras-multi-head-0.28.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.15.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/e1/0da586d544a0940a56a2f4aa704b7dbd95eaa8ceda6168b48f5ac95e6608/keras-layer-normalization-0.15.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/58/02/cd3e7e51cf45d3825818384a2f7d9c340b60c9bf55a5682b7318e1c16eab/keras-position-wise-feed-forward-0.7.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/2d/48/78f6d134f1ede597d91186819c9e428ada51cd8d9ea28e5faf37ed2ee602/keras-embed-sim-0.9.0.tar.gz\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert<6->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (0.5.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (1.9.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev>=0.2.38->fastbook->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 8)) (0.10.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow_gpu>=2.0->-r MBD-EN-BL-ENE-2020-J-1/requirements.txt (line 10)) (3.1.1)\n",
            "Collecting keras-self-attention>=0.50.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/75/e6bc5b43ee968fef714f2f10a2a1674639ec85d2428cc47b2fe1f9af0115/keras-self-attention-0.50.0.tar.gz\n",
            "Building wheels for collected packages: ktrain, eli5, stellargraph, networkx, langdetect, syntok, seqeval, keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.26.3-cp37-none-any.whl size=25282390 sha256=3fbd3470c9feaed189745103f383c8981a72a11c780df290b524b1c65c51b306\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/05/be/d6e659b3349016b1059e19fa028f165af4eeae2c196f329112\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eli5: filename=eli5-0.10.1-py2.py3-none-any.whl size=106850 sha256=f4d81c8bc482684b949d5800216e2b29bc1773ec3d450a2719d2ff23f9fd42c9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gy9ymvdi/wheels/51/59/0a/0f48442b8d209583a4453580938d7ba2270aca40edacee6d45\n",
            "  Building wheel for stellargraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stellargraph: filename=stellargraph-0.8.2-cp37-none-any.whl size=146391 sha256=eff0b22ce0a8fa5cfae2c6f5a2afa039db16f01fa269309a5db32a02036d0aa8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gy9ymvdi/wheels/29/6d/9d/505e95c414d36910e5c319ce9e63dc641973b2c6a2e2e16044\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556427 sha256=e73a1f7b8db3df99b06caa35391efd4082e4ae8b998268b6cdf8eccbfb41d11b\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-cp37-none-any.whl size=993242 sha256=e316c6de19441a17bbee630f414a80cf51ff163c5dfbf93ec3ea99422334903c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/18/13/038c34057808931c7ddc6c92d3aa015cf1a498df5a70268996\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syntok: filename=syntok-1.3.1-cp37-none-any.whl size=20919 sha256=6cca1b6022986421d68736b93383f3dea951d1f4161c86cd469c279be8433260\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/c6/a4/be1920586c49469846bcd2888200bdecfe109ec421dab9be2d\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.19-cp37-none-any.whl size=9932 sha256=4ca6d43a230faa503642d0a89824254c3781068a2289c511a2631900e740c855\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/1f/bf/1198beceed805a2099060975f6281d1b01046dd279e19c97be\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.88.0-cp37-none-any.whl size=34206 sha256=b4cf04675010b03910d70f6ce7d56715daff9167e9e6ccae83292ce438ba2a69\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/d8/86/b4d91b941f6f3256c487b258d5e4268a3301203b717dd11f11\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.39.0-cp37-none-any.whl size=12841 sha256=ae66ad2789f10868e96c8e11c6c4c72ee4d2d945380b8b988f9a3d4420fe0748\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/42/35/d33c5907bca04ac5742e9eceefb644b680286de26728506a70\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.12.0-cp37-none-any.whl size=7471 sha256=8a9679dd5ed9de378c0e81f2dbcacdc15420b7b6c70f1487c95345c62973ef81\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/d8/36/06ed09215806dca9ff504d8c0dda5da68d7f2c67d34a231d82\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.28.0-cp37-none-any.whl size=15559 sha256=b4d3a70931d05f38a1397d996a6087359399eedea93947ad0a1496b52a949212\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/92/bd/b3407bc29501f7e28eb970a6c425a9a375485c5d8197df6a8f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.15.0-cp37-none-any.whl size=5224 sha256=b8d6c52a61e6b56d81ae6979695f4d86ef6bf572695ab70f0cc75d7b11361543\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/ea/db/833c8a9b8326e703e9f8a78c0d4153294e6a1b1f97a1836397\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.7.0-cp37-none-any.whl size=5542 sha256=f9c3efd4eae896da628510700b729b844ef9e2a7e56e5c48b0504b97eb1fceb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/d2/f6/58ce0aae0055dbccba8b40e62a6c22ab997105ad8c431a9e80\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.9.0-cp37-none-any.whl size=4505 sha256=3ca3d3f1c2a686037b9cb7d12a4e703a0481d356f6d5099f92ae4b7f7e2085e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/d5/7d/bef5ee93c88bc6150294cc74cbb081647c505bf816918dd7ff\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.50.0-cp37-none-any.whl size=19416 sha256=bf3edfe5ce4712bba54ddc783982173fddd3b015b5170cb7506bb3be38e4b45b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/93/0d/891573db60f74d0e43bd7db1496c3ef898f8b5946a4c24cbda\n",
            "Successfully built ktrain eli5 stellargraph networkx langdetect syntok seqeval keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastbook 0.0.16 has requirement fastai>=2.1, but you'll have fastai 1.0.61 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: ktrain 0.26.3 has requirement scikit-learn==0.23.2, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: ktrain 0.26.3 has requirement transformers<=4.3.3,>=4.0.0, but you'll have transformers 4.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: elasticsearch, sentencepiece, fastcore, ghapi, fastrelease, nbdev, fastbook, tensorflow-gpu, langdetect, cchardet, syntok, seqeval, sacremoses, huggingface-hub, tokenizers, transformers, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, networkx, whoosh, ktrain, eli5, stellargraph\n",
            "  Found existing installation: networkx 2.5.1\n",
            "    Uninstalling networkx-2.5.1:\n",
            "      Successfully uninstalled networkx-2.5.1\n",
            "Successfully installed cchardet-2.1.7 elasticsearch-7.13.1 eli5-0.10.1 fastbook-0.0.16 fastcore-1.3.20 fastrelease-0.1.11 ghapi-0.1.17 huggingface-hub-0.0.8 keras-bert-0.88.0 keras-embed-sim-0.9.0 keras-layer-normalization-0.15.0 keras-multi-head-0.28.0 keras-pos-embd-0.12.0 keras-position-wise-feed-forward-0.7.0 keras-self-attention-0.50.0 keras-transformer-0.39.0 ktrain-0.26.3 langdetect-1.0.9 nbdev-1.1.14 networkx-2.3 sacremoses-0.0.45 sentencepiece-0.1.96 seqeval-0.0.19 stellargraph-0.8.2 syntok-1.3.1 tensorflow-gpu-2.5.0 tokenizers-0.10.3 transformers-4.7.0 whoosh-2.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXlB1ILg5ONr"
      },
      "source": [
        "# Imports and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "XAHXbPsD_9Oq",
        "outputId": "04230bce-618e-466e-ffab-bbdf272730a3"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\")) # Increase cell width\n",
        "display(HTML(\"<style>.rendered_html { font-size: 16px; }</style>\")) # Increase font size\n",
        "\n",
        "# Matplotlib conf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Seaborn conf\n",
        "import seaborn as sns\n",
        "sns.set_palette(sns.color_palette(\"seismic\"))\n",
        "\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "import tensorflow as tf\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/train.csv')\n",
        "\n",
        "df = df.drop(columns=['qid'])\n",
        "print(df.head())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.rendered_html { font-size: 16px; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "                                       question_text  target\n",
            "0  How did Quebec nationalists see their province...       0\n",
            "1  Do you have an adopted dog, how would you enco...       0\n",
            "2  Why does velocity affect time? Does velocity a...       0\n",
            "3  How did Otto von Guericke used the Magdeburg h...       0\n",
            "4  Can I convert montra helicon D to a mountain b...       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhgXVfXj_9PC"
      },
      "source": [
        "## Inspecting the data\n",
        "\n",
        "The dataset is taken from Kaggle competition (Quora Insincere Questions Classification)\n",
        "\n",
        "\n",
        "An insincere question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is insincere:\n",
        "\n",
        "- Has a non-neutral tone\n",
        "\n",
        " - Has an exaggerated tone to underscore a point about a group of people\n",
        " - Is rhetorical and meant to imply a statement about a group of people\n",
        "- Is disparaging or inflammatory\n",
        "\n",
        " - Suggests a discriminatory idea against a protected class of people, or seeks confirmation of a stereotype\n",
        " - Makes disparaging attacks/insults against a specific person or group of people\n",
        " - Based on an outlandish premise about a group of people\n",
        " - Disparages against a characteristic that is not fixable and not measurable \n",
        "- Isn't grounded in reality\n",
        " - Based on false information, or contains absurd assumptions\n",
        " - Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers\n",
        "\n",
        "The training data includes the question that was asked, and whether it was identified as insincere (target = 1)\n",
        "### Class distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJXZCZcV_9PC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "30bfbde9-efeb-4289-ae56-d2339d5e833d"
      },
      "source": [
        "sns.countplot(x=df.target, order=[x for x, count in sorted(Counter(df.target).items(), key=lambda x: -x[1])], palette=\"seismic\")\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lwll1MbFV6k"
      },
      "source": [
        "The target class has around 60k records, where as the non-target has 1.2 million records. This is a clear example of a class imbalance classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TacHyhsetfiI"
      },
      "source": [
        "# Modelling with Transforerms\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmiEA41murJY"
      },
      "source": [
        "## Create the Transformer Model\n",
        "\n",
        "First, we will preprocess the dataset with ktrain library, create a Text Classifier based on a Transformer model.\n",
        "\n",
        "\n",
        "Then we start with a Language Model pre-trained using a massive dataset. The model is BERT where it applies the idea of Self-Attention (instead of an RNN architecture) to learn the sequential information of textual contents.\n",
        "\n",
        "\n",
        "It is needed to fine-tune this model, so we will re-train the model to our specific dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "HQF4dgZLu39d",
        "outputId": "05f28c3b-0b26-4d7a-f87a-64c042c57ee4"
      },
      "source": [
        "trn, val, preproc = text.texts_from_df(df,'question_text',preprocess_mode='bert',label_columns='target',verbose=True, maxlen=32) # Process the input questions based on the BERT encoder\n",
        "\n",
        "model = text.text_classifier('bert', trn, preproc=preproc) # Create a text classifier that uses the BERT-based representations created before\n",
        "\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=val,  batch_size=128) # Creates the learning process to fine-tune bert and train the classifier."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['not_target', 'target']\n",
            "        not_target  target\n",
            "316565         1.0     0.0\n",
            "951115         1.0     0.0\n",
            "55210          1.0     0.0\n",
            "122975         1.0     0.0\n",
            "791368         1.0     0.0\n",
            "['not_target', 'target']\n",
            "         not_target  target\n",
            "614888          1.0     0.0\n",
            "1140011         1.0     0.0\n",
            "810856          1.0     0.0\n",
            "625054          1.0     0.0\n",
            "231097          1.0     0.0\n",
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 32\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU9diVmz1vc8"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "It is now time to actually train (fine-tuning + train the text classifier) the model. This process might take a while. BERT is huge and memory-hungry. Consequently, it is pretty slow for both training and prediction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD5f-vk21lXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8facb7e-3eab-4d38-ff84-adc0fa35b642"
      },
      "source": [
        "learner.lr_find(show_plot=True, max_epochs=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "simulating training for different learning rates... this may take a few moments...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   4/9184 [..............................] - ETA: 86:26:25 - loss: 0.2644 - accuracy: 0.9316"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gU-GYCt2PSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577f9895-fbbc-4ee5-ff3a-2e221525a672"
      },
      "source": [
        "learner.autofit(lr=1e-4, # Learning Rate \n",
        "                epochs=1, # Number of epochs to train the model\n",
        "                early_stopping=1, # If the model does not improve after 2 epochs, we stop the training\n",
        "                reduce_on_plateau=1,  # If the model does not improve aftear 1 epoch, we reduce the learning rate\n",
        "                monitor='val_loss', # Metric to monitor the peformance of the model (loss computed on the validation dataset)\n",
        "                checkpoint_folder='transformer_cpt_1' # After each epoch we store a checkpoint of the model\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.0001...\n",
            "9184/9184 [==============================] - 9743s 1s/step - loss: 0.1013 - accuracy: 0.9595 - val_loss: 0.0905 - val_accuracy: 0.9636\n",
            "Weights from best epoch have been loaded into model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f305cedb050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4t8kmXzoMSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ea17af-784e-43a3-ff2f-529668387a42"
      },
      "source": [
        "learner.save_model('transformer_1') # Saving the trained model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho6eSo9IcI3_"
      },
      "source": [
        "# Evaluate and Inspect the Model\n",
        "\n",
        "Large Deep Learning models are well-known for being quite black-boxy. However, in this section, I would like to provide you with some tools to evaluate and analyze them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvTuKoSmV0lY"
      },
      "source": [
        "Below is the confussion matrix to understand the performance of the model and to check the accuracy and F-measure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvcxCvLOcOje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efc7efc-823f-4eaa-d9dc-f63b8ce81d81"
      },
      "source": [
        "learner.validate(class_names=['Normal Question','Abnormal Question'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "  Normal Question       0.98      0.98      0.98    122386\n",
            "Abnormal Question       0.72      0.68      0.70      8227\n",
            "\n",
            "         accuracy                           0.96    130613\n",
            "        macro avg       0.85      0.83      0.84    130613\n",
            "     weighted avg       0.96      0.96      0.96    130613\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[120240,   2146],\n",
              "       [  2607,   5620]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43qyNa66Znba"
      },
      "source": [
        "ktrain, actually provides an `explain` method to know that. It allows you to inspect a given tweet and visualize which words contributed the most on deciding the final prediction. We will need a forked version of the **eli5** library that supportes TensorFlow Keras, so let's install it first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6HjLF9dd5iZ",
        "outputId": "37a7cd4a-8cb6-479b-9b25-9061f069a885"
      },
      "source": [
        "!pip3 install -q git+https://github.com/amaiya/eli5@tfkeras_0_10_1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByXyFJY_bUrn"
      },
      "source": [
        "And call the `explain` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "3HgZDLYUeVaM",
        "outputId": "7e7f40ae-a17f-4d01-e1ca-b5c17f643a5b"
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc)\n",
        "\n",
        "predictor.explain(\"can we prevent women from voting?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=target\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.625</b>, score <b>0.513</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.717\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.39%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.205\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 99.75%); opacity: 0.80\" title=\"0.003\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.82%); opacity: 0.84\" title=\"0.854\">we</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.93%); opacity: 0.85\" title=\"1.159\">prevent</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"4.673\">women</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.01%); opacity: 0.83\" title=\"0.644\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.58%); opacity: 0.81\" title=\"0.269\">voting</span><span style=\"opacity: 0.80\">?</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTF5dL4PLLmk"
      },
      "source": [
        "# Re-load the trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW9XrzwbivWO"
      },
      "source": [
        "reloaded_predictor = ktrain.load_predictor('/content/gdrive/MyDrive/TeamB_predictor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sGpHbOJjPfM",
        "outputId": "c5703261-7158-4e7f-984b-bf879b311ac4"
      },
      "source": [
        "data = ['can women vote?']\n",
        "\n",
        "reloaded_predictor.predict(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not_target']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdSmqoNJRJup"
      },
      "source": [
        "\n",
        "### With model interpretability using eli5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "5ttknqAlOkDC",
        "outputId": "031241ab-18c4-4598-fa3f-7c468b5a0094"
      },
      "source": [
        "reloaded_predictor.explain(\"can we prevent women from voting or not?\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=target\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.608</b>, score <b>0.437</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.568\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.09%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.131\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 99.03%); opacity: 0.80\" title=\"0.023\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.26%); opacity: 0.84\" title=\"0.904\">we</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.78%); opacity: 0.87\" title=\"1.507\">prevent</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"4.632\">women</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.40%); opacity: 0.82\" title=\"0.353\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.72%); opacity: 0.82\" title=\"0.406\">voting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.21%); opacity: 0.81\" title=\"-0.293\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.15%); opacity: 0.80\" title=\"0.106\">not</span><span style=\"opacity: 0.80\">?</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}